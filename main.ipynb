{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfec4U6jb2TY+3blw+T4pV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import whisper\n",
        "import base64\n",
        "import cv2\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "from groq import Groq\n",
        "import torch\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "import whisper\n",
        "import os\n",
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_core.documents import Document\n",
        "from langchain.vectorstores import FAISS\n",
        "from groq import Groq\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "UhTmZ-4ByNtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Whisper model\n",
        "whisper_model = whisper.load_model(\"base\")"
      ],
      "metadata": {
        "id": "CHObU7GryNvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "   model_name=\"llama-3.1-8b-instant\",\n",
        "   api_key=\"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\",\n",
        "   temperature = 0.4\n",
        ")"
      ],
      "metadata": {
        "id": "s3ElBjdVyNxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process audio files\n",
        "def process_audio(file_path):\n",
        "    if file_path.endswith(\".mp3\"):  # Process only .mp3 files\n",
        "        # Transcribe the audio file\n",
        "        transcription = whisper_model.transcribe(file_path, fp16=False)[\"text\"].strip()\n",
        "\n",
        "        # Extract the file name from the path\n",
        "        file_name = os.path.basename(file_path)\n",
        "\n",
        "        # Create a Document with transcription and audio reference\n",
        "        document = Document(\n",
        "            page_content=transcription,\n",
        "            metadata={\"source_type\": \"audio\", \"audio_file_name\": file_name, \"audio_file_path\": file_path}\n",
        "        )\n",
        "        return [document]"
      ],
      "metadata": {
        "id": "amGk2pFX32gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process PDF files\n",
        "def process_pdf(pdf_file):\n",
        "    loader = PyPDFLoader(pdf_file)\n",
        "    pdf_docs = loader.load()\n",
        "\n",
        "    # Add metadata for each PDF document\n",
        "    for doc in pdf_docs:\n",
        "        doc.metadata.update({\"source_type\": \"pdf\", \"pdf_file_name\": os.path.basename(pdf_file), \"pdf_file_path\": pdf_file})\n",
        "    return pdf_docs"
      ],
      "metadata": {
        "id": "JoHFsR9333zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract frames from video and process them\n",
        "def extract_frames_from_video(video_path, output_folder):\n",
        "    # Clear the output folder if it already exists\n",
        "    if os.path.exists(output_folder):\n",
        "        for filename in os.listdir(output_folder):\n",
        "            file_path = os.path.join(output_folder, filename)\n",
        "            if os.path.isfile(file_path):\n",
        "                os.unlink(file_path)\n",
        "\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    video_capture = cv2.VideoCapture(video_path)\n",
        "    fps = video_capture.get(cv2.CAP_PROP_FPS)\n",
        "    frame_count = int(video_capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    if fps == 0:\n",
        "        print(\"Unable to retrieve FPS from video. Exiting.\")\n",
        "        return []\n",
        "\n",
        "    duration = frame_count / fps\n",
        "    success, image = video_capture.read()\n",
        "    frame_number = 0\n",
        "    frames = []\n",
        "\n",
        "    while success:\n",
        "        # Save the first frame, every 5 seconds, and the last frame\n",
        "        if frame_number == 0 or frame_number % int(fps * 5) == 0 or frame_number == frame_count - 1:\n",
        "            frame_time = frame_number / fps\n",
        "            output_frame_filename = os.path.join(output_folder, f'frame_{int(frame_time)}.jpg')\n",
        "            cv2.imwrite(output_frame_filename, image)\n",
        "            frames.append(output_frame_filename)\n",
        "\n",
        "        success, image = video_capture.read()\n",
        "        frame_number += 1\n",
        "\n",
        "    video_capture.release()\n",
        "    return frames"
      ],
      "metadata": {
        "id": "rVK1882lyN1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to encode the image\n",
        "def encode_image(image_path):\n",
        "    with open(image_path, \"rb\") as image_file:\n",
        "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
      ],
      "metadata": {
        "id": "YFOu80c84G6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process video frames and create vector database\n",
        "def process_video_frames(image_directory):\n",
        "    if not os.path.exists(image_directory):\n",
        "        raise FileNotFoundError(f\"The directory {image_directory} does not exist.\")\n",
        "\n",
        "    # Extract video name from directory path\n",
        "    video_name = os.path.basename(image_directory)\n",
        "\n",
        "    # Initialize Groq client\n",
        "    client = Groq(api_key=\"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\")  # Replace with your API key\n",
        "\n",
        "    # List to store Document instances\n",
        "    documents = []\n",
        "\n",
        "    # Iterate through all images in the directory\n",
        "    for filename in os.listdir(image_directory):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
        "            image_path = os.path.join(image_directory, filename)\n",
        "\n",
        "            # Get the base64 string\n",
        "            base64_image = encode_image(image_path)\n",
        "\n",
        "            # Create chat completion for the current image\n",
        "            chat_completion = client.chat.completions.create(\n",
        "                messages=[{\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\"type\": \"text\", \"text\": f\"What's in this image? ({filename})\"},\n",
        "                        {\n",
        "                            \"type\": \"image_url\",\n",
        "                            \"image_url\": {\n",
        "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
        "                            },\n",
        "                        },\n",
        "                    ],\n",
        "                }],\n",
        "                model=\"meta-llama/llama-4-maverick-17b-128e-instruct\",\n",
        "            )\n",
        "\n",
        "            # Create a Document from the output and store it in the documents list\n",
        "            doc = Document(\n",
        "                page_content=chat_completion.choices[0].message.content,\n",
        "                metadata={\n",
        "                    \"image_filename\": filename,\n",
        "                    \"video_name\": video_name,\n",
        "                }\n",
        "            )\n",
        "            documents.append(doc)\n",
        "\n",
        "    return documents"
      ],
      "metadata": {
        "id": "nllEy4oayqSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to split documents into chunks and create a vector database\n",
        "def create_vector_db(documents):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=64)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "\n",
        "    # Create embeddings and vector database\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", model_kwargs={\"device\": \"cpu\"})\n",
        "    db = FAISS.from_documents(texts, embeddings)\n",
        "    db.save_local(\"vector_db\")\n",
        "\n",
        "    return db"
      ],
      "metadata": {
        "id": "oAmCNYPFyqU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def query_vector_database(db, question):\n",
        "    results = db.similarity_search(question, k=5)\n",
        "    source_knowledge = \"\\n\".join([doc.page_content for doc in results])\n",
        "    metadata = [doc.metadata for doc in results]\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    [INST]<<SYS>>\n",
        "    Based on this example, complete the task below.<</SYS>>\n",
        "    Context: {source_knowledge}\n",
        "    Question: {question}\n",
        "    Metadata: {metadata}\n",
        "\n",
        "    Answer based on the context:\n",
        "    [/INST]\n",
        "    \"\"\"\n",
        "\n",
        "    # Assuming `llm.invoke` to generate the final response\n",
        "    llm_response = llm.invoke(prompt)\n",
        "    if hasattr(llm_response, \"content\"):\n",
        "        answer = llm_response.content.strip()\n",
        "    else:\n",
        "        answer = str(llm_response).strip()\n",
        "\n",
        "\n",
        "    # Prepare the final result\n",
        "    res = {\n",
        "        \"answer\": answer,\n",
        "        \"metadata\": [\n",
        "            {\n",
        "                \"file_name\": doc.metadata.get(\"audio_file_name\") or doc.metadata.get(\"pdf_file_name\") or doc.metadata.get(\"image_filename\", \"\"),\n",
        "                \"file_path\": doc.metadata.get(\"audio_file_path\") or doc.metadata.get(\"pdf_file_path\") or \"\",\n",
        "                \"video_name\": doc.metadata.get(\"video_name\", \"\"),\n",
        "            }\n",
        "            for doc in results\n",
        "        ],\n",
        "    }\n",
        "\n",
        "    # Remove duplicate metadata entries\n",
        "    unique_metadata = []\n",
        "    seen = set()\n",
        "    for entry in res[\"metadata\"]:\n",
        "        metadata_tuple = (entry[\"file_name\"], entry[\"file_path\"], entry[\"video_name\"])\n",
        "        if metadata_tuple not in seen:\n",
        "            unique_metadata.append(entry)\n",
        "            seen.add(metadata_tuple)\n",
        "\n",
        "    res[\"metadata\"] = unique_metadata\n",
        "\n",
        "    return res"
      ],
      "metadata": {
        "id": "X12S9qHZ4Ram"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        # Ask user for file type and query\n",
        "        file_type = input(\"Enter the file path (audio/pdf/video): \")\n",
        "\n",
        "        # Process the file based on user input\n",
        "        if file_type.endswith(\".mp3\"):\n",
        "            documents = process_audio(file_type)\n",
        "\n",
        "        elif file_type.endswith(\".pdf\"):\n",
        "            documents = process_pdf(file_type)\n",
        "\n",
        "        elif file_type.endswith(\".mp4\"):\n",
        "            image_directory = \"video_frames\"\n",
        "            frames = extract_frames_from_video(file_type, image_directory)\n",
        "            documents = process_video_frames(image_directory)\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid file type. Please choose from audio, pdf, or video.\")\n",
        "            exit()\n",
        "\n",
        "        # Create vector database\n",
        "        db = create_vector_db(documents)\n",
        "        print(\"Vector database created successfully.\")\n",
        "\n",
        "        query = input(\"Enter your query: \").strip()\n",
        "\n",
        "        # Query the vector database\n",
        "        result = query_vector_database(db, query)\n",
        "\n",
        "        print(\"\\nAnswer:\", result[\"answer\"])\n",
        "        print(\"\\nRelated Metadata:\")\n",
        "        for metadata in result[\"metadata\"]:\n",
        "            if metadata[\"file_name\"]:\n",
        "                print(f\"File Name: {metadata['file_name']}\")\n",
        "            if metadata[\"file_path\"]:\n",
        "                print(f\"File Path: {metadata['file_path']}\")\n",
        "            if metadata[\"video_name\"]:\n",
        "                print(f\"Video Name: {metadata['video_name']}\")\n",
        "            print()\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")"
      ],
      "metadata": {
        "id": "XHIgnEopyqYf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}